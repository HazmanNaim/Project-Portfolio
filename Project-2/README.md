# Differentiating Galaxies, Quasars, and Stars through Utilization of Various Classification Algorithms with SDSS Sky Survey Data
Duration: 3 Days
## Purpose:
This project aims to develop a machine learning model for categorizing galaxies, stars, and quasars using SDSS data. Similar to other cosmological surveys, SDSS contributes an exceptional volume of data generated by the telescope and instruments. Notably, the telescope produced hundreds of gigabytes of raw data every night, a scale that was previously unprecedented. The manual classification of each object requires a significant amount of labor and proves to be inefficient in terms of both cost and time. To simplify this resource-intensive process, the application of machine learning emerges as a solution to enhance efficiency in astronomical research. This highlights the valuable utility of machine learning, which excels in deciphering intricate patterns within large datasets, fundamentally transforming the landscape of the astronomical domain.

## Methodology:
I utilized a comprehensive dataset comprising 100,000 observed samples from Data Release 18 of the Sloan Digital Sky Survey (SDSS). This dataset was sourced from Kaggle and can be accessed through this ([Kaggle Dataset](https://www.kaggle.com/datasets/diraf0/sloan-digital-sky-survey-dr18)) link. Following that, I conducted exploratory data analysis, which involved refining the data and exploring correlations and associations among the features within the dataset. The subsequent phase encompassed the construction of machine learning models based on the processed datasets.

To accomplish this, I employed a range of machine learning techniques, including logistic regression, support vector classifier, and the random forest classifier provided by scikit-learn.

Throughout this notebook, essential pre-processing steps were applied to the dataset, such as data scaling to ensure standardization. Additionally, I implemented 5-fold cross-validation to reliably assess the performance of the models, while also conducting hyperparameter tuning to fine-tune their effectiveness. The notebook also incorporates visualizations that effectively showcase the models' performance, including the use of a confusion matrix to demonstrate the accuracy of object classification achieved by the models.

## Tools/Tech
![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

## Challenges Encountered
1. The project encountered challenges primarily stemming from hardware limitations. The use of a low-specification computer significantly impeded progress. Tasks such as model tuning, which necessitate numerous iterations, were notably delayed due to hardware constraints. For instance, the time required to fine-tune the model was substantially extended, hindering the overall workflow.

## Outcomes
**Results**

The project involved the development of 7 distinct machine learning models utilizing various algorithms. These models included logistic regression, support vector classifier, and the random forest classifier. 

A summary of the models' performance metrics is provided below:


| Model                     | Model Alias           | Detail                                              | Accuracy (Train) | Log Loss (Train) | Accuracy (Test) | Log Loss (Test) | Cross-validated Accuracy (Test) |
|---------------------------|-----------------------|-----------------------------------------------------|------------------|------------------|-----------------|-----------------|--------------------------------|
| Logistic Regression       | lr1                   | Default                                             | 0.915412         | 0.342063         | 0.91395         | 0.35147         | 0.91400                        |
| Logistic Regression       | lr2                   | Default, Scaled                                    | 0.989838         | 0.050864         | 0.98840         | 0.058638        | 0.98931                        |
| Support Vector Classifier | svm1                  | Default                                             | 0.918162         | -                | 0.91310         | -               | 0.78097                        |
| Support Vector Classifier | svm2                  | Default, Scaled                                    | 0.990550         | -                | 0.98860         | -               | 0.98908                        |
| Random Forest Classifier  | rf1                   | Default                                             | 1.000000         | -                | 0.99085         | -               | 0.99104                        |
| Random Forest Classifier  | rf2                   | Default, Scaled                                    | 1.000000         | -                | 0.99115         | -               | 0.99142                        |
| Random Forest Classifier  | rf3                   | min_samples_split=6, min_samples_leaf=1, max_f... | 1.000000         | -                | 0.99150         | -               | 0.99217                        |

From the provided summary table about how well models predict house prices using 5-fold cross-validation, we can learn some useful things:

In this project, several machine learning models were trained and evaluated for the task of classifying galaxies, stars, and QSOs from SDSS data.

**Scaled vs Unscaled**: The performance of Logistic Regression (lr1 and lr2) and Support Vector Classifier (svm1 and svm2) models improved when the data was scaled. Specifically, the accuracy of lr2 increased to 98.93% from 91.40% of lr1, and the accuracy of svm2 increased to 98.90% from 78.10% of svm1.

**Model Comparison**: Among Logistic Regression (lr1 and lr2), Support Vector Classifier (svm1 and svm2), and Random Forest Classifier (rf1, rf2, rf3), the Random Forest Classifier models performed the best in terms of accuracy, achieving perfect training accuracy (100%) and high test accuracies (rf1: 99.10%, rf2: 99.14%, rf3: 99.21%).

**Tuned vs Non-Tuned**: Tuning the parameters of the Random Forest Classifier (rf3) improved its performance compared to the non-tuned versions (rf1 and rf2). The test accuracy of rf3 increased to 99.21% from 99.10% of rf1 and 99.14% of rf2.

In conclusion, this project successfully implemented and evaluated several machine learning models for classifying astronomical objects. The tuned Random Forest Classifier (rf3) demonstrated the best performance.

## Further Enhancements
1. Given a longer time duration, it would be beneficial to delve into more advanced machine learning models beyond the ones already explored. Models such as Gradient Boosting, or Neural Networks could be studied to potentially yield even more accurate predictions.
2. Testing the models on entirely separate datasets, including those not used during training or evaluation, can provide a more realistic assessment of their predictive accuracy and generalization to new data.
3. To ensure that the models are trained with the most relevant features, a more comprehensive approach to feature selection could be implemented. For instance, conducting techniques like Recursive Feature Elimination could be considered. This process iteratively identifies and removes less influential features, ultimately enhancing the model's ability to capture meaningful patterns and relationships within the data.
